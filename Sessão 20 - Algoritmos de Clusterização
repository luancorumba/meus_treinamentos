{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["lJeDRY2Zc6Tn"],"authorship_tag":"ABX9TyPclVCS/HyvLrZNhKma0vO4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["###### Inicialização"],"metadata":{"id":"lJeDRY2Zc6Tn"}},{"cell_type":"code","source":["# instalar as dependências\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://dlcdn.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n","!tar xf spark-3.4.0-bin-hadoop3.tgz\n","!pip install -q findspark"],"metadata":{"id":"ty_kN91oadtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# configurar as variáveis de ambiente\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\"\n","\n","# tornar o pyspark \"importável\"\n","import findspark\n","findspark.init('spark-3.4.0-bin-hadoop3')"],"metadata":{"id":"GMGdL4xyc423"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# download do http para arquivo local\n","!wget --quiet --show-progress http://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2023-03-28/visualisations/listings.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRro-0ZO38tf","executionInfo":{"status":"ok","timestamp":1688344380300,"user_tz":180,"elapsed":39,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"ba40e155-e8ac-4e6b-9d6a-a34afcfeb44b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["listings.csv        100%[===================>]   4.37M  24.3MB/s    in 0.2s    \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from matplotlib import pyplot as plt\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as f\n","from pyspark.ml.functions import vector_to_array\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import StandardScaler, VectorAssembler\n","\n","spark = SparkSession.builder.master('local[*]').getOrCreate()\n","sc = spark.sparkContext"],"metadata":{"id":"Nm6FyqyPzm4C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PySpark (Sessão 20)"],"metadata":{"id":"frFI5O7cZ5L8"}},{"cell_type":"markdown","source":["![img](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/250px-Apache_Spark_logo.svg.png)\n","\n","\n","https://spark.apache.org/docs/latest/api/python/"],"metadata":{"id":"pJCODccgTiQD"}},{"cell_type":"markdown","source":["## Recapitulando o que vimos antes..."],"metadata":{"id":"bGI5IDjEL5Z7"}},{"cell_type":"markdown","source":["1. Introdução ao Clustering\n","2. Analisando Distribuições\n","3. Algoritmo de K-Means\n","4. Avaliação de modelos de clustering"],"metadata":{"id":"s9LmwhGkwhOJ"}},{"cell_type":"markdown","source":["- https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe\n","- https://medium.com/airbnb-engineering/building-airbnb-categories-with-ml-human-in-the-loop-35b78a837725\n","- https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1\n","- https://medium.com/analytics-vidhya/model-based-recommendation-system-with-matrix-factorization-als-model-and-the-math-behind-fdce8b2ffe6d"],"metadata":{"id":"LOmK1gHibB8l"}},{"cell_type":"markdown","source":["## Preparando os dados"],"metadata":{"id":"ShKzmzPvFgZ6"}},{"cell_type":"code","source":["airbnb_rj = spark.read.csv(\"./listings.csv\", inferSchema=True, header=True)\n","airbnb_rj = airbnb_rj.where(airbnb_rj.host_id.cast(\"int\").isNotNull())\n","airbnb_rj = airbnb_rj.withColumn(\"host_id\", airbnb_rj.host_id.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"price\", f.log(airbnb_rj.price.cast('int'))) # agora aplicando o log\n","airbnb_rj = airbnb_rj.withColumn(\"minimum_nights\", airbnb_rj.minimum_nights.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"number_of_reviews\", airbnb_rj.number_of_reviews.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"reviews_per_month\", airbnb_rj.reviews_per_month.cast('double'))\n","airbnb_rj = airbnb_rj.withColumn(\"availability_365\", airbnb_rj.availability_365.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"number_of_reviews_ltm\", airbnb_rj.number_of_reviews_ltm.cast('double'))\n","airbnb_rj = airbnb_rj.withColumn(\"calculated_host_listings_count\", airbnb_rj.calculated_host_listings_count.cast('int'))"],"metadata":{"id":"GZ36GBIvFivN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bairros_isolados = airbnb_rj.groupBy(airbnb_rj.neighbourhood). \\\n","                                agg(f.count(\"id\").alias(\"contagem\")). \\\n","                                where(\"contagem < 10\").select(airbnb_rj.neighbourhood). \\\n","                                toPandas().neighbourhood.tolist()\n","airbnb_rj = airbnb_rj.where(~airbnb_rj.neighbourhood.isin(bairros_isolados)) #existe apenas um ítem na base"],"metadata":{"id":"jNzN290MFlF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["continuas = [\"minimum_nights\", \"number_of_reviews\", \"reviews_per_month\",\n","     \"calculated_host_listings_count\", \"availability_365\", \"number_of_reviews_ltm\", \"price\"]"],"metadata":{"id":"S72fwj3rFqzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["airbnb_rj = airbnb_rj.fillna(0, subset = continuas)"],"metadata":{"id":"5iGhUCoaFrB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["treino, teste = airbnb_rj.select(*(continuas)).randomSplit([0.7, 0.3])"],"metadata":{"id":"MDFEVI_5p0q8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stages = []"],"metadata":{"id":"CAWuF3VfphQ6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Combinaremos todas as colunas de recurso em um vetor"],"metadata":{"id":"5TYA-N4gb3UM"}},{"cell_type":"code","source":["selecao_final = [\"minimum_nights\", \"number_of_reviews\", \"reviews_per_month\",\n","     \"calculated_host_listings_count\", \"availability_365\", \"number_of_reviews_ltm\", \"price\"]\n","assembler = VectorAssembler(inputCols=selecao_final, outputCol='features')\n","stages += [assembler]"],"metadata":{"id":"jdsibzyaVDrU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Escalaremos as variáveis utilizando o StandardScaler"],"metadata":{"id":"CHw5VHetF_PU"}},{"cell_type":"code","source":["scaler = StandardScaler(inputCol='features', outputCol='features_scaled')\n","stages += [scaler]"],"metadata":{"id":"4qYE4Md55GjX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Transformaremos os dados para estarem prontos para aplicarmos os modelos"],"metadata":{"id":"t738mMASGSaN"}},{"cell_type":"code","source":["pipeline = Pipeline(stages=stages)\n","preparacao = pipeline.fit(treino)"],"metadata":{"id":"WhAdhX1lY_WE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["treino = preparacao.transform(treino).select('features_scaled')\n","teste = preparacao.transform(teste).select('features_scaled')"],"metadata":{"id":"Ryhb67VmcNWw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Algoritmo de LDA"],"metadata":{"id":"w_GXUXTITQuX"}},{"cell_type":"markdown","source":["Análise de Latent Dirichlet Allocation (LDA) é um método de modelagem de tópicos que visa explicar as relações entre observações (como palavras em um documento) através de tópicos não observados (ou latentes). É muito usado em processamento de linguagem natural e outras áreas que lidam com dados textuais.\n","\n","Funcionamento do LDA:\n","\n","1. O LDA começa por assumir que existem K tópicos nos dados.\n","Em seguida, atribui cada palavra em cada documento a um tópico. Esta atribuição é feita de forma aleatória no início.\n","2. A partir daí, para cada documento, o LDA vai passar por cada palavra e atribuí-la a um tópico. A probabilidade de uma palavra ser atribuída a um tópico é baseada na proporção de palavras já atribuídas a esse tópico e na proporção de palavras em todo o documento que já foram atribuídas a esse tópico.\n","3. Este processo é repetido muitas vezes e os tópicos resultantes são usados para classificar os documentos.\n","4. A implementação do LDA no MLlib do PySpark segue esses passos. Aqui está um exemplo de código:"],"metadata":{"id":"-GXkksvt0bDA"}},{"cell_type":"code","source":["from pyspark.ml.clustering import LDA\n","\n","# Treinando um modelo LDA.\n","lda = LDA(featuresCol='features_scaled', k=10, maxIter=10)\n","model = lda.fit(treino)"],"metadata":{"id":"_-Ely_rm0ac_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Descrevendo tópicos.\n","topics = model.describeTopics(3)\n","topics.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJ5NO07Twyu0","executionInfo":{"status":"ok","timestamp":1688344670546,"user_tz":180,"elapsed":16,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"abd0b77a-c5f0-48b6-884c-f39b3c49f026"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+-----------+---------------------------------------------------------------+\n","|topic|termIndices|termWeights                                                    |\n","+-----+-----------+---------------------------------------------------------------+\n","|0    |[6, 2, 5]  |[0.35653520398385197, 0.23488295114328145, 0.2244999384265818] |\n","|1    |[3, 6, 4]  |[0.8388375585283352, 0.089108041557391, 0.035865409660594726]  |\n","|2    |[6, 4, 2]  |[0.7041103532917073, 0.21447365460198167, 0.028077332485730275]|\n","|3    |[6, 1, 5]  |[0.33477376828773353, 0.3048925074897531, 0.17040756303354943] |\n","|4    |[1, 4, 2]  |[0.1631009414638125, 0.15007598054470778, 0.14690923543974235] |\n","|5    |[3, 5, 6]  |[0.15829920179252127, 0.1534464134326561, 0.1517896042053789]  |\n","|6    |[6, 2, 5]  |[0.652485940727189, 0.11159758978020824, 0.07036337782226613]  |\n","|7    |[0, 6, 4]  |[0.8519022754142479, 0.09772878960675441, 0.025933460293204605]|\n","|8    |[3, 0, 1]  |[0.1543125535468668, 0.14619980957355727, 0.1460676815739143]  |\n","|9    |[0, 6, 3]  |[0.5922371942566484, 0.10243367417702087, 0.10178275199632253] |\n","+-----+-----------+---------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Em termos de desempenho, o LDA pode lidar com grandes conjuntos de dados e é relativamente eficiente em termos computacionais. Além disso, a implementação do LDA no PySpark pode ser executada em paralelo em várias máquinas, o que pode acelerar ainda mais o processo.\n","\n","No entanto, o LDA tem algumas limitações:\n","\n","1. O número de tópicos (K) precisa ser definido previamente. Isso pode ser uma desvantagem, pois muitas vezes não sabemos qual é o número \"correto\" de tópicos.\n","2. O LDA assume que os documentos são produzidos a partir de uma mistura de tópicos e que cada palavra é atribuível a um tópico. Este pode não ser o caso em todos os cenários.\n","3. A interpretação dos tópicos pode ser desafiadora, especialmente quando o número de tópicos é grande."],"metadata":{"id":"1Na8Tzu69CVW"}},{"cell_type":"markdown","source":["Os principais hiperparâmetros do LDA no MLlib incluem:\n","\n","- k: O número de tópicos desejados nos dados.\n","maxIter: O número máximo de iterações que o algoritmo pode executar.\n","- docConcentration: Parâmetro de concentração Dirichlet para o modelo por documento. Este valor controla a distribuição dos tópicos em cada documento.\n","- topicConcentration: Parâmetro de concentração Dirichlet para o modelo por tópico. Este valor controla a distribuição das palavras em cada tópico.\n","- optimizer: O otimizador a ser usado. Pode ser 'online' ou 'em'. 'em' refere-se ao método de maximização da expectativa, enquanto"],"metadata":{"id":"2k9Hs6m-9IHM"}},{"cell_type":"markdown","source":["## Modelos de Misturas Gaussianas (Gaussian Mixture Models)"],"metadata":{"id":"3CEXI2mL9SwX"}},{"cell_type":"markdown","source":["<center>\n","<img src=\"https://miro.medium.com/v2/resize:fit:640/0*CdbBWmL6lYllndI4\"/>\n","</center>"],"metadata":{"id":"jDSUhzPQ_3hk"}},{"cell_type":"markdown","source":["O algoritmo Gaussian Mixture Models (GMM) é um modelo de clusterização que assume que todos os pontos de dados são gerados a partir de uma mistura de um número finito de distribuições gaussianas com parâmetros desconhecidos. Ele tenta identificar essas distribuições gaussianas e seus parâmetros. O GMM é um método de \"soft clustering\", o que significa que cada ponto de dados é atribuído a um cluster com uma certa probabilidade, ao contrário do \"hard clustering\" onde cada ponto de dados é atribuído a exatamente um cluster.\n","\n","Aqui está um exemplo de código de como o GMM pode ser implementado no MLlib:"],"metadata":{"id":"BJf8Qoxh9XoF"}},{"cell_type":"code","source":["from pyspark.ml.clustering import GaussianMixture\n","\n","# Instanciar o GMM\n","gmm = GaussianMixture(featuresCol='features_scaled', k = 4, seed = 123)\n","\n","# Ajustar o modelo\n","model = gmm.fit(treino)"],"metadata":{"id":"nBXGg_4Z9f22"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Output dos parâmetros do modelo\n","print(\"Gaussians mostrados como vetores de ponderações, médias e covariancias.\")\n","for i in range(2):\n","    print(\"weight = \", model.weights[i], \"mu = \", model.gaussians[i].mean,\n","           \"sigma = \", model.gaussians[i].cov)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RUm1MaimMg8t","executionInfo":{"status":"ok","timestamp":1688344888430,"user_tz":180,"elapsed":415,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"ed8e5357-bfeb-49b7-c33d-fd5bed923f56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Gaussians mostrados como vetores de ponderações, médias e covariancias.\n","weight =  0.1784161730206658 mu =  [0.16389018131687083,0.1767300840276842,1.1056012352594196,0.596505203124594,1.561268961095833,0.4014957886110863,6.212906299070151] sigma =  DenseMatrix([[ 0.84070792, -0.00314554, -0.07134238, -0.01341664, -0.01494963,\n","              -0.0165874 ,  0.04233032],\n","             [-0.00314554,  0.11688374,  0.09158765, -0.01851126, -0.02513712,\n","               0.10417427, -0.0373259 ],\n","             [-0.07134238,  0.09158765,  1.53481   , -0.33469048, -0.05030019,\n","               0.34871492, -0.43000692],\n","             [-0.01341664, -0.01851126, -0.33469048,  0.38482836, -0.03224286,\n","              -0.07182851,  0.31053038],\n","             [-0.01494963, -0.02513712, -0.05030019, -0.03224286,  0.94540443,\n","              -0.04787433,  0.01598021],\n","             [-0.0165874 ,  0.10417427,  0.34871492, -0.07182851, -0.04787433,\n","               0.22434729, -0.11702627],\n","             [ 0.04233032, -0.0373259 , -0.43000692,  0.31053038,  0.01598021,\n","              -0.11702627,  1.36088174]])\n","weight =  0.22065018547983473 mu =  [0.12716721521537627,1.5962436250755683,1.6110223688535965,0.08156407290238687,1.2428248950896872,1.83766418976453,5.724034725614694] sigma =  DenseMatrix([[ 6.11716602e-01, -2.16847378e-02, -4.25584743e-02,\n","               2.17836986e-04, -3.00992390e-03, -5.11122630e-02,\n","               2.79959955e-02],\n","             [-2.16847378e-02,  2.37646888e+00,  5.50192591e-01,\n","               9.25110759e-03, -3.58127269e-02,  9.83931904e-01,\n","              -5.33882921e-02],\n","             [-4.25584743e-02,  5.50192591e-01,  1.19499629e+00,\n","               3.44103874e-03, -1.40851436e-02,  1.07628870e+00,\n","              -5.91334299e-02],\n","             [ 2.17836986e-04,  9.25110759e-03,  3.44103874e-03,\n","               7.44893081e-03,  1.55565341e-03,  7.77231843e-03,\n","              -9.84985591e-04],\n","             [-3.00992390e-03, -3.58127269e-02, -1.40851436e-02,\n","               1.55565341e-03,  7.33831122e-01,  3.82315225e-02,\n","               2.91238075e-02],\n","             [-5.11122630e-02,  9.83931904e-01,  1.07628870e+00,\n","               7.77231843e-03,  3.82315225e-02,  1.68340293e+00,\n","              -9.06079230e-02],\n","             [ 2.79959955e-02, -5.33882921e-02, -5.91334299e-02,\n","              -9.84985591e-04,  2.91238075e-02, -9.06079230e-02,\n","               4.75272886e-01]])\n"]}]},{"cell_type":"markdown","source":["Quanto ao desempenho, o GMM é mais computacionalmente caro do que o k-means, pois precisa estimar mais parâmetros.\n","\n","Quanto às limitações, como a maioria dos algoritmos de clustering, o GMM também precisa que o número de clusters seja especificado previamente. Além disso, o GMM assume que os dados são uma mistura de distribuições gaussianas, o que pode não ser adequado para todos os conjuntos de dados."],"metadata":{"id":"eAZYzDXO9ivR"}},{"cell_type":"markdown","source":["Os principais hiperparâmetros do GMM no MLlib incluem:\n","\n","- k: Número de componentes gaussianas independentes no modelo de mistura.\n","- maxIter: O número máximo de iterações que o algoritmo pode executar.\n","- tol: A tolerância de convergência para parar a iteração.\n","- seed: A semente para a geração de números aleatórios. Isso é usado para inicializar as responsabilidades se nenhum ponto inicial for dado."],"metadata":{"id":"YkpFm4Xq9oy2"}},{"cell_type":"markdown","source":["## Bisecting K-Means"],"metadata":{"id":"kcDW8n110bug"}},{"cell_type":"markdown","source":["<center>\n","<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*-JqsJLWUPJtQWaH-ANBN5A.png\"/>\n","</center>"],"metadata":{"id":"siH8GOmUAf4X"}},{"cell_type":"markdown","source":["O Bisecting K-means é uma variação do algoritmo K-means que busca produzir uma hierarquia de clusters. Ele começa com todos os objetos em um único cluster. Depois, os dados são divididos iterativamente em dois clusters (daí o \"bisecting\"). O cluster a ser dividido é aquele que resulta na maior redução da soma dos erros quadrados (SSE). Este processo é repetido até que o número desejado de clusters seja atingido.\n","\n","Aqui está um exemplo de como o Bisecting K-means pode ser implementado no PySpark MLlib:"],"metadata":{"id":"kFs5WCwV0cJ2"}},{"cell_type":"code","source":["from pyspark.ml.clustering import BisectingKMeans\n","\n","# Trains a bisecting k-means model\n","bkm = BisectingKMeans(featuresCol='features_scaled', k = 8, seed = 123)\n","\n","model = bkm.fit(treino)"],"metadata":{"id":"ZVGrShYyTib8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Avaliação\n","cost = model.computeCost(treino)\n","print(\"Within Set Sum of Squared Errors = \" + str(cost))\n","\n","# Mostra os resultados\n","print(\"Cluster Centers: \")\n","centers = model.clusterCenters()\n","for center in centers:\n","    print(center)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abUQ4sKqM_47","executionInfo":{"status":"ok","timestamp":1688345002466,"user_tz":180,"elapsed":1086,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"b70afc8f-3b0c-4988-f68e-244c595013d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/spark-3.4.0-bin-hadoop3/python/pyspark/ml/clustering.py:1016: FutureWarning: Deprecated in 3.0.0. It will be removed in future versions. Use ClusteringEvaluator instead. You can also get the cost on the training dataset in the summary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Within Set Sum of Squared Errors = 70102.99418895914\n","Cluster Centers: \n","[0.36585618 0.08623969 0.18780686 0.68744937 2.50242646 0.11527764\n"," 7.40013786]\n","[0.13818195 0.19589202 0.50832488 0.21238057 2.47117157 0.3053657\n"," 5.69480006]\n","[0.19912519 0.22967173 0.46912408 0.1763151  0.60240384 0.29502498\n"," 6.03949876]\n","[0.26437936 0.13642957 0.29087282 5.64588879 0.48231515 0.20848291\n"," 7.08642468]\n","[0.08012289 0.73042648 3.00172539 0.30088812 1.3242963  2.14283545\n"," 5.70588559]\n","[0.11111716 1.90434215 1.40085741 0.21359206 1.13975609 1.97147598\n"," 5.691278  ]\n","[0.10310505 3.90178625 2.93583938 0.16075203 1.16348428 3.77112215\n"," 5.62488949]\n","[0.08901632 8.00802865 3.46733309 0.11432752 1.32733608 4.44715827\n"," 5.50458531]\n"]}]},{"cell_type":"code","source":["from pyspark.ml.evaluation import ClusteringEvaluator\n","\n","# Fazendo previsões\n","predictions = model.transform(treino)\n","\n","evaluator = ClusteringEvaluator(featuresCol='features_scaled')\n","silhouette = evaluator.evaluate(predictions)\n","print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVdderHK1zAD","executionInfo":{"status":"ok","timestamp":1688345036435,"user_tz":180,"elapsed":2651,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"a16e8145-92ad-4546-90d3-44e48cf5c2df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Silhouette with squared euclidean distance = 0.2866905085713695\n"]}]},{"cell_type":"markdown","source":["## Conclusão da sessão"],"metadata":{"id":"u20jBuvdTcBG"}},{"cell_type":"markdown","source":["1. Algoritmo LDA\n","2. Algoritmo GMM\n","3. Algotitmo Bisecting K-Means"],"metadata":{"id":"qmkkKK_sTdan"}},{"cell_type":"markdown","source":["## Exercício"],"metadata":{"id":"NCnmlbdJaB0S"}},{"cell_type":"markdown","source":["1. Explique a diferença entre LDA e Bisecting K-Means.\n","2. Implemente o LDA em um conjunto de dados de sua escolha.\n","3. Implemente o Bisecting K-Means em um conjunto de dados  de sua escolha.\n","4. Como avaliamos modelos de clustering em PySpark?\n","5. Avalie os modelos que você implementou nos exercícios 2 e 3."],"metadata":{"id":"uRc2Gm8iJpon"}}]}