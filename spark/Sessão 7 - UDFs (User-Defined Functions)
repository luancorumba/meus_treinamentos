{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["lJeDRY2Zc6Tn"],"authorship_tag":"ABX9TyOWQIPk25CzwAuFolPK8XUY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["###### Inicialização"],"metadata":{"id":"lJeDRY2Zc6Tn"}},{"cell_type":"code","source":["# instalar as dependências\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://dlcdn.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n","!tar xf spark-3.4.0-bin-hadoop3.tgz\n","!pip install -q findspark"],"metadata":{"id":"ty_kN91oadtM","executionInfo":{"status":"ok","timestamp":1683082664637,"user_tz":180,"elapsed":35362,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# configurar as variáveis de ambiente\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\"\n","\n","# tornar o pyspark \"importável\"\n","import findspark\n","findspark.init('spark-3.4.0-bin-hadoop3')"],"metadata":{"id":"GMGdL4xyc423","executionInfo":{"status":"ok","timestamp":1683082664643,"user_tz":180,"elapsed":26,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# download do http para arquivo local\n","!wget --quiet --show-progress http://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2023-03-28/visualisations/listings.csv"],"metadata":{"id":"qRro-0ZO38tf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683082665299,"user_tz":180,"elapsed":251,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"432f1bff-f492-4875-d9d6-a108c065cd6e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\rlistings.csv          0%[                    ]       0  --.-KB/s               \rlistings.csv        100%[===================>]   4.37M  27.4MB/s    in 0.2s    \n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master('local[*]').getOrCreate()\n","sc = spark.sparkContext"],"metadata":{"id":"E953zalteJfG","executionInfo":{"status":"ok","timestamp":1683082677874,"user_tz":180,"elapsed":12581,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# PySpark (Sessão 7)"],"metadata":{"id":"frFI5O7cZ5L8"}},{"cell_type":"markdown","source":["![img](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/250px-Apache_Spark_logo.svg.png)\n","\n","\n","https://spark.apache.org/docs/latest/api/python/"],"metadata":{"id":"Mdadd0ioeYO2"}},{"cell_type":"markdown","source":["## Recapitulando o que vimos antes..."],"metadata":{"id":"bGI5IDjEL5Z7"}},{"cell_type":"markdown","source":["1. Gravação de arquivos (txt, csv, json, parquet, SGBDs)\n","2. Leitura de arquivos (txt, csv, json, parquet, SGBDs)"],"metadata":{"id":"-obvnmiNbwcp"}},{"cell_type":"code","source":["airbnb_rj = spark.read.csv(\"./listings.csv\", inferSchema=True, header=True)\n","airbnb_rj = airbnb_rj.where(airbnb_rj.host_id.cast(\"int\").isNotNull())\n","airbnb_rj = airbnb_rj.withColumn(\"host_id\", airbnb_rj.host_id.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"price\", airbnb_rj.price.cast('int'))\n","airbnb_rj"],"metadata":{"id":"IoAeTskF4M9b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683082740029,"user_tz":180,"elapsed":19706,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"286f0a8e-713a-42ae-b506-f7f8646a10ef"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[id: string, name: string, host_id: int, host_name: string, neighbourhood_group: string, neighbourhood: string, latitude: string, longitude: string, room_type: string, price: int, minimum_nights: string, number_of_reviews: string, last_review: string, reviews_per_month: string, calculated_host_listings_count: string, availability_365: string, number_of_reviews_ltm: double, license: int]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Introdução às UDFs"],"metadata":{"id":"cH8SM-ANLofl"}},{"cell_type":"markdown","source":["As UDFs (User-Defined Functions) no PySpark são funções personalizadas criadas pelo usuário que podem ser aplicadas aos dados durante o processamento em um Apache Spark DataFrame. As UDFs permitem que você estenda a funcionalidade padrão do PySpark e aplique operações específicas aos seus dados, que podem não estar disponíveis nas funções internas do PySpark.\n","\n","Para criar uma UDF no PySpark, você precisa seguir três passos:\n","\n","1. Defina uma função Python que implementa a lógica desejada.\n","2. Registre a função Python como uma UDF usando a função ```udf()``` do PySpark.\n","3. Aplique a UDF registrada aos dados do DataFrame."],"metadata":{"id":"iP1hIUzYSbz5"}},{"cell_type":"code","source":["from pyspark.sql.functions import udf\n","from pyspark.sql.types import StringType\n","\n","# Defina a função Python que implementa a lógica desejada\n","def to_upper_case(s):\n","    return s.upper()\n","\n","# Registre a função Python como uma UDF\n","to_upper_case_udf = udf(to_upper_case, StringType())\n","\n","# Aplique a UDF registrada aos dados do DataFrame\n","df_upper_case = airbnb_rj.withColumn(\"Name_Upper_Case\", to_upper_case_udf(airbnb_rj[\"name\"]))\n","df_upper_case.show()"],"metadata":{"id":"jrdZ1dxWSgiR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683083001296,"user_tz":180,"elapsed":2514,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"9cba7e0f-c448-4c26-e31e-9317aba18f24"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+--------------------+-------+--------------------+-------------------+---------------+----------+----------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-------+--------------------+\n","|    id|                name|host_id|           host_name|neighbourhood_group|  neighbourhood|  latitude| longitude|      room_type|price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|number_of_reviews_ltm|license|     Name_Upper_Case|\n","+------+--------------------+-------+--------------------+-------------------+---------------+----------+----------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-------+--------------------+\n","| 17878|Very Nice 2Br in ...|  68997|            Matthias|               null|     Copacabana| -22.96599|  -43.1794|Entire home/apt|  350|             5|              288| 2023-03-01|             1.86|                             1|             264|                 19.0|   null|VERY NICE 2BR IN ...|\n","| 24480|Nice and cozy nea...|  99249|                Goya|               null|        Ipanema| -22.98405| -43.20189|Entire home/apt|  624|             3|               86| 2023-03-27|             0.56|                             3|             357|                  1.0|   null|NICE AND COZY NEA...|\n","|200568|30m of Ipa Beach ...| 980805|            Henrique|               null|        Ipanema| -22.98586| -43.19411|Entire home/apt|  100|            30|              198| 2023-02-13|             1.45|                             6|              59|                  9.0|   null|30M OF IPA BEACH ...|\n","|342874|Comfortable in Co...| 829630|             Luciana|               null|           Leme| -22.96392| -43.17263|Entire home/apt|  236|             2|              159| 2023-02-26|             1.19|                             3|             105|                 31.0|   null|COMFORTABLE IN CO...|\n","| 25026|Beautiful Modern ...| 102840|             Viviane|               null|     Copacabana| -22.97735| -43.19105|Entire home/apt|  307|             3|              262| 2023-03-27|             1.68|                             1|             257|                 14.0|   null|BEAUTIFUL MODERN ...|\n","|202778|Best Studio in Ri...| 529105|                Alex|               null|     Copacabana| -22.96582| -43.17786|Entire home/apt|  266|             3|              223| 2023-03-08|             1.58|                             3|             356|                 10.0|   null|BEST STUDIO IN RI...|\n","| 35764|COPACABANA SEA BR...| 153691|Patricia Miranda ...|               null|     Copacabana| -22.98107| -43.19136|Entire home/apt|  180|             3|              428| 2023-03-21|             2.82|                             1|              53|                 40.0|   null|COPACABANA SEA BR...|\n","| 48305|Bright 6bed Penth...|  70933|             Goitaca|               null|        Ipanema| -22.98591| -43.20302|Entire home/apt| 2270|             2|              136| 2023-03-19|             0.92|                             9|             254|                 34.0|   null|BRIGHT 6BED PENTH...|\n","|203674|IPANEMA PENTHOUSE...| 999125|            Alastair|               null|        Ipanema| -22.98335| -43.20306|Entire home/apt| 1899|             5|               48| 2019-05-07|             0.36|                             1|             268|                  0.0|   null|IPANEMA PENTHOUSE...|\n","|210173|BEAUTIFUL! Spacio...|1030316|           Elizabeth|               null|     Copacabana| -22.98596| -43.19001|   Private room| 1576|             2|                3| 2019-10-03|             0.02|                             3|             365|                  0.0|   null|BEAUTIFUL! SPACIO...|\n","|215793|BEAUTIFUL! Spacio...|1030316|           Elizabeth|               null|     Copacabana| -22.98596| -43.19001|   Private room|  427|             2|               39| 2023-02-23|             0.28|                             3|             259|                  6.0|   null|BEAUTIFUL! SPACIO...|\n","|344463|Ocean front 2 sui...|1762102|               Hilda|               null|Barra da Tijuca|  -23.0098| -43.37099|Entire home/apt|  539|             3|               65| 2022-09-05|             0.51|                             2|             217|                  1.0|   null|OCEAN FRONT 2 SUI...|\n","| 48901|Confortable 4BD 3...| 222884|              Marcio|               null|     Copacabana| -22.96574| -43.17514|Entire home/apt|  627|             3|               13| 2023-03-12|             0.14|                             2|             354|                  5.0|   null|CONFORTABLE 4BD 3...|\n","|346694|Alugo quarto espa...|1612576|            Jassanan|               null|  Vila da Penha| -22.84208| -43.31572|   Private room|  340|             1|                0|       null|             null|                             1|             362|                  0.0|   null|ALUGO QUARTO ESPA...|\n","|215887|BEAUTIFUL! Spacio...|1030316|           Elizabeth|               null|     Copacabana| -22.98596| -43.19001|   Private room|  214|             2|               39| 2023-02-22|             0.28|                             3|             255|                  5.0|   null|BEAUTIFUL! SPACIO...|\n","| 49179|Djalma Ocean View...| 224192|               David|               null|     Copacabana|  -22.9791| -43.19008|Entire home/apt|  200|             4|              133| 2023-03-20|             1.06|                            21|             132|                 14.0|   null|DJALMA OCEAN VIEW...|\n","| 51703|Ocean view, block...| 238091|               Dália|               null|     Copacabana|-22.981731|-43.190571|Entire home/apt|  178|             3|              233| 2023-03-25|             1.80|                             2|             326|                 30.0|   null|OCEAN VIEW, BLOCK...|\n","|216461|Comfortable room ...|1154263|         Zeilma , Da|               null|       Flamengo|  -22.9399| -43.17676|   Private room|  780|             1|                0|       null|             null|                             1|             365|                  0.0|   null|COMFORTABLE ROOM ...|\n","|347295|Copa Penthouse Br...|1603206|                 Bob|               null|     Copacabana| -22.96654| -43.18248|Entire home/apt|  197|             3|               75| 2023-03-19|             0.56|                             5|             333|                  2.0|   null|COPA PENTHOUSE BR...|\n","| 53533|Walk to Joatinga ...| 249439|      Sherri & Andre|               null|            Joá| -23.00809| -43.29113|Entire home/apt| 1355|             2|               31| 2023-02-23|             0.22|                             1|             332|                 13.0|   null|WALK TO JOATINGA ...|\n","+------+--------------------+-------+--------------------+-------------------+---------------+----------+----------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-------+--------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["As UDFs no PySpark são úteis quando você deseja aplicar operações específicas aos dados que não podem ser realizadas usando as funções internas do PySpark. No entanto, as UDFs geralmente têm um desempenho inferior às funções internas, pois o Spark precisa executar a função Python para cada registro no DataFrame. Sempre que possível, é recomendável usar funções internas do PySpark para obter melhor desempenho."],"metadata":{"id":"Ynj4GK-MSn4Z"}},{"cell_type":"markdown","source":["### Funções Internas"],"metadata":{"id":"mAIWuPqDZwnj"}},{"cell_type":"markdown","source":["As built-in functions (funções internas) do PySpark são funções predefinidas fornecidas pelo Apache Spark para realizar diversas operações de processamento de dados nos DataFrames e RDDs. Essas funções são otimizadas para desempenho e podem ser aplicadas diretamente aos dados sem a necessidade de criar funções personalizadas (UDFs).\n","\n","As funções internas do PySpark abrangem várias categorias, incluindo funções matemáticas, de string, de data e hora, de agregação, de janela e outras. Algumas das funções internas comuns do PySpark são:\n","\n","- ```concat```: Concatena duas ou mais colunas de string.\n","substring: Extrai uma substring de uma coluna de string.\n","- ```lower``` e ```upper```: Converte uma coluna de string em letras minúsculas ou maiúsculas.\n","- ```count```: Conta o número de linhas em um grupo.\n","- ```sum```: Calcula a soma de uma coluna numérica em um grupo.\n","- ```avg```: Calcula a média de uma coluna numérica em um grupo.\n","- ```min``` e ```max```: Encontra o valor mínimo ou máximo de uma coluna em um grupo.\n","- ```when``` e ```otherwise```: Permite expressar condições lógicas para criar uma nova coluna com base nos valores das colunas existentes.\n","\n","Para usar as funções internas do PySpark, você precisa importá-las do módulo pyspark.sql.functions. Aqui está um exemplo de como usar algumas funções internas do PySpark em um DataFrame:"],"metadata":{"id":"JXwOaFLmZ1Ef"}},{"cell_type":"code","source":["from pyspark.sql.functions import col, upper, length, when\n","\n","# Aplica funções internas do PySpark ao DataFrame\n","df = airbnb_rj.withColumn(\"Name_Upper\", upper(col(\"name\"))) \\\n","       .withColumn(\"Name_Length\", length(col(\"name\"))) \\\n","       .withColumn(\"Long_Name\", when(col(\"Name_Length\") > 20, \"Long\").otherwise(\"Short\"))\n","\n","df.show()"],"metadata":{"id":"Ap1FQf2hZ_fd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683083230820,"user_tz":180,"elapsed":1509,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"f60474da-51e1-4938-9d2c-8e0974f6cd68"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+--------------------+-------+--------------------+-------------------+---------------+----------+----------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-------+--------------------+-----------+---------+\n","|    id|                name|host_id|           host_name|neighbourhood_group|  neighbourhood|  latitude| longitude|      room_type|price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|number_of_reviews_ltm|license|          Name_Upper|Name_Length|Long_Name|\n","+------+--------------------+-------+--------------------+-------------------+---------------+----------+----------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-------+--------------------+-----------+---------+\n","| 17878|Very Nice 2Br in ...|  68997|            Matthias|               null|     Copacabana| -22.96599|  -43.1794|Entire home/apt|  350|             5|              288| 2023-03-01|             1.86|                             1|             264|                 19.0|   null|VERY NICE 2BR IN ...|         49|     Long|\n","| 24480|Nice and cozy nea...|  99249|                Goya|               null|        Ipanema| -22.98405| -43.20189|Entire home/apt|  624|             3|               86| 2023-03-27|             0.56|                             3|             357|                  1.0|   null|NICE AND COZY NEA...|         48|     Long|\n","|200568|30m of Ipa Beach ...| 980805|            Henrique|               null|        Ipanema| -22.98586| -43.19411|Entire home/apt|  100|            30|              198| 2023-02-13|             1.45|                             6|              59|                  9.0|   null|30M OF IPA BEACH ...|         49|     Long|\n","|342874|Comfortable in Co...| 829630|             Luciana|               null|           Leme| -22.96392| -43.17263|Entire home/apt|  236|             2|              159| 2023-02-26|             1.19|                             3|             105|                 31.0|   null|COMFORTABLE IN CO...|         31|     Long|\n","| 25026|Beautiful Modern ...| 102840|             Viviane|               null|     Copacabana| -22.97735| -43.19105|Entire home/apt|  307|             3|              262| 2023-03-27|             1.68|                             1|             257|                 14.0|   null|BEAUTIFUL MODERN ...|         41|     Long|\n","|202778|Best Studio in Ri...| 529105|                Alex|               null|     Copacabana| -22.96582| -43.17786|Entire home/apt|  266|             3|              223| 2023-03-08|             1.58|                             3|             356|                 10.0|   null|BEST STUDIO IN RI...|         31|     Long|\n","| 35764|COPACABANA SEA BR...| 153691|Patricia Miranda ...|               null|     Copacabana| -22.98107| -43.19136|Entire home/apt|  180|             3|              428| 2023-03-21|             2.82|                             1|              53|                 40.0|   null|COPACABANA SEA BR...|         47|     Long|\n","| 48305|Bright 6bed Penth...|  70933|             Goitaca|               null|        Ipanema| -22.98591| -43.20302|Entire home/apt| 2270|             2|              136| 2023-03-19|             0.92|                             9|             254|                 34.0|   null|BRIGHT 6BED PENTH...|         40|     Long|\n","|203674|IPANEMA PENTHOUSE...| 999125|            Alastair|               null|        Ipanema| -22.98335| -43.20306|Entire home/apt| 1899|             5|               48| 2019-05-07|             0.36|                             1|             268|                  0.0|   null|IPANEMA PENTHOUSE...|         50|     Long|\n","|210173|BEAUTIFUL! Spacio...|1030316|           Elizabeth|               null|     Copacabana| -22.98596| -43.19001|   Private room| 1576|             2|                3| 2019-10-03|             0.02|                             3|             365|                  0.0|   null|BEAUTIFUL! SPACIO...|         29|     Long|\n","|215793|BEAUTIFUL! Spacio...|1030316|           Elizabeth|               null|     Copacabana| -22.98596| -43.19001|   Private room|  427|             2|               39| 2023-02-23|             0.28|                             3|             259|                  6.0|   null|BEAUTIFUL! SPACIO...|         30|     Long|\n","|344463|Ocean front 2 sui...|1762102|               Hilda|               null|Barra da Tijuca|  -23.0098| -43.37099|Entire home/apt|  539|             3|               65| 2022-09-05|             0.51|                             2|             217|                  1.0|   null|OCEAN FRONT 2 SUI...|         35|     Long|\n","| 48901|Confortable 4BD 3...| 222884|              Marcio|               null|     Copacabana| -22.96574| -43.17514|Entire home/apt|  627|             3|               13| 2023-03-12|             0.14|                             2|             354|                  5.0|   null|CONFORTABLE 4BD 3...|         37|     Long|\n","|346694|Alugo quarto espa...|1612576|            Jassanan|               null|  Vila da Penha| -22.84208| -43.31572|   Private room|  340|             1|                0|       null|             null|                             1|             362|                  0.0|   null|ALUGO QUARTO ESPA...|         35|     Long|\n","|215887|BEAUTIFUL! Spacio...|1030316|           Elizabeth|               null|     Copacabana| -22.98596| -43.19001|   Private room|  214|             2|               39| 2023-02-22|             0.28|                             3|             255|                  5.0|   null|BEAUTIFUL! SPACIO...|         30|     Long|\n","| 49179|Djalma Ocean View...| 224192|               David|               null|     Copacabana|  -22.9791| -43.19008|Entire home/apt|  200|             4|              133| 2023-03-20|             1.06|                            21|             132|                 14.0|   null|DJALMA OCEAN VIEW...|         49|     Long|\n","| 51703|Ocean view, block...| 238091|               Dália|               null|     Copacabana|-22.981731|-43.190571|Entire home/apt|  178|             3|              233| 2023-03-25|             1.80|                             2|             326|                 30.0|   null|OCEAN VIEW, BLOCK...|         50|     Long|\n","|216461|Comfortable room ...|1154263|         Zeilma , Da|               null|       Flamengo|  -22.9399| -43.17676|   Private room|  780|             1|                0|       null|             null|                             1|             365|                  0.0|   null|COMFORTABLE ROOM ...|         34|     Long|\n","|347295|Copa Penthouse Br...|1603206|                 Bob|               null|     Copacabana| -22.96654| -43.18248|Entire home/apt|  197|             3|               75| 2023-03-19|             0.56|                             5|             333|                  2.0|   null|COPA PENTHOUSE BR...|         34|     Long|\n","| 53533|Walk to Joatinga ...| 249439|      Sherri & Andre|               null|            Joá| -23.00809| -43.29113|Entire home/apt| 1355|             2|               31| 2023-02-23|             0.22|                             1|             332|                 13.0|   null|WALK TO JOATINGA ...|         50|     Long|\n","+------+--------------------+-------+--------------------+-------------------+---------------+----------+----------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+---------------------+-------+--------------------+-----------+---------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["## Tipos de UDFs em PySpark\n"],"metadata":{"id":"7wLafL_ALrcL"}},{"cell_type":"markdown","source":["No PySpark, as UDFs (User-Defined Functions) podem ser classificadas em três categorias com base em sua funcionalidade e implementação: **UDFs escalares, UDFs vetoriais e UDFs agregadas.**"],"metadata":{"id":"awpqx0JPXYBj"}},{"cell_type":"markdown","source":["### UDFs escalares\n"],"metadata":{"id":"Q8Zid9R9YBHM"}},{"cell_type":"markdown","source":["São UDFs que processam os dados um registro de cada vez, aplicando a função personalizada definida pelo usuário a cada registro individualmente. UDFs regulares são um exemplo de UDFs escalares. Para criar uma UDF escalar no PySpark, você precisa definir uma função Python que implementa a lógica desejada e registrá-la como uma UDF usando a função ```udf()``` do PySpark."],"metadata":{"id":"zNCrCtG1YC_e"}},{"cell_type":"code","source":["from pyspark.sql.functions import udf\n","from pyspark.sql.types import IntegerType\n","\n","# Defina a função Python que implementa a lógica desejada\n","def multiply_by_factor(value, factor=2):\n","    return value * factor\n","\n","# Registre a função Python como uma UDF escalar\n","multiply_by_factor_udf = udf(multiply_by_factor, returnType=IntegerType())\n","\n","# Aplique a UDF escalar registrada aos dados do DataFrame\n","df_with_udf = airbnb_rj.select(multiply_by_factor_udf(airbnb_rj[\"price\"]).alias(\"Multiplied_Price\"))\n","df_with_udf.show()\n"],"metadata":{"id":"fECIDG8WXqG6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683083345548,"user_tz":180,"elapsed":30,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"94d74240-3c76-4bcf-de59-940bca11e5c5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------+\n","|Multiplied_Price|\n","+----------------+\n","|             700|\n","|            1248|\n","|             200|\n","|             472|\n","|             614|\n","|             532|\n","|             360|\n","|            4540|\n","|            3798|\n","|            3152|\n","|             854|\n","|            1078|\n","|            1254|\n","|             680|\n","|             428|\n","|             400|\n","|             356|\n","|            1560|\n","|             394|\n","|            2710|\n","+----------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["### UDFs vetoriais "],"metadata":{"id":"4eGvf-fpX7Wp"}},{"cell_type":"markdown","source":["Também conhecidas como UDFs Pandas, são UDFs otimizadas que utilizam a biblioteca Pandas para processar dados em lote. As UDFs vetoriais aplicam a função personalizada a um conjunto de registros de uma vez, usando DataFrames Pandas como entrada e saída, o que melhora o desempenho e reduz o tempo de execução. Para criar uma UDF vetorial no PySpark, você precisa definir uma função Python que aceita e retorna DataFrames Pandas e registrá-la como uma UDF Pandas usando a função ```pandas_udf()``` do PySpark."],"metadata":{"id":"lhsCTpjaX9f4"}},{"cell_type":"code","source":["import pandas as pd\n","from pyspark.sql.functions import pandas_udf, PandasUDFType\n","from pyspark.sql.types import DoubleType\n","\n","# Ativar o suporte a Arrow para melhorar o desempenho\n","spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n","\n","# Defina a função Python que implementa a lógica desejada\n","def sqrt_pandas(series: pd.Series) -> pd.Series:\n","    return series ** 0.5\n","\n","# Registre a função Python como uma UDF vetorial\n","sqrt_pandas_udf = pandas_udf(sqrt_pandas, returnType=DoubleType(), functionType=PandasUDFType.SCALAR)\n","\n","# Aplique a UDF vetorial registrada aos dados do DataFrame\n","df_with_udf = airbnb_rj.select(sqrt_pandas_udf(airbnb_rj[\"price\"]).alias(\"Square_Root\"))\n","df_with_udf.show()"],"metadata":{"id":"pO9ZxnXdYEd_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683083577585,"user_tz":180,"elapsed":2452,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"aedbf4cb-b7ee-498f-8114-da2ff286b8e2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/spark-3.4.0-bin-hadoop3/python/pyspark/sql/pandas/functions.py:399: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["+------------------+\n","|       Square_Root|\n","+------------------+\n","|18.708286933869708|\n","|24.979991993593593|\n","|              10.0|\n","|15.362291495737216|\n","| 17.52141546793523|\n","| 16.30950643030009|\n","|13.416407864998739|\n","|47.644516998286385|\n","| 43.57751713900185|\n","|39.698866482558415|\n","|20.663978319771825|\n","|  23.2163735324878|\n","| 25.03996805109783|\n","|18.439088914585774|\n","|14.628738838327793|\n","|14.142135623730951|\n","|13.341664064126334|\n","| 27.92848008753788|\n","|14.035668847618199|\n","|36.810324638611924|\n","+------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["### UDFs agregadas"],"metadata":{"id":"c795a1A5Xpba"}},{"cell_type":"markdown","source":["São UDFs usadas para agregar dados em grupos, semelhantes às funções de agregação internas, como sum, count, avg, etc. As UDFs agregadas podem ser criadas com a biblioteca Pandas para melhor desempenho. Para criar uma UDF agregada no PySpark, você precisa definir duas funções Python: uma para calcular o resultado parcial da agregação para cada grupo e outra para combinar os resultados parciais em um resultado final. Em seguida, registre a UDF agregada usando a função ```pandas_udf()``` com o argumento ```functionType=PandasUDFType.GROUPED_AGG```."],"metadata":{"id":"zuc_pJ-xX3I0"}},{"cell_type":"code","source":["# Defina a função Python que implementa a lógica desejada\n","def custom_mean(series: pd.Series) -> float:\n","    return series.mean()\n","\n","# Registre a função Python como uma UDF Pandas\n","custom_mean_udf = pandas_udf(custom_mean, returnType=DoubleType(), functionType=PandasUDFType.GROUPED_AGG)\n","\n","# Aplique a UDF agregada registrada aos dados do DataFrame\n","df_grouped = airbnb_rj.groupBy(\"neighbourhood\").agg(custom_mean_udf(airbnb_rj[\"price\"]).alias(\"Mean_price\"))\n","df_grouped.show()"],"metadata":{"id":"vJcDco4oXqq3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683083717204,"user_tz":180,"elapsed":3648,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"6af97946-a6dd-4966-f383-47d82c59b83d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------+------------------+\n","|     neighbourhood|        Mean_price|\n","+------------------+------------------+\n","|          Abolição|             465.5|\n","|             Acari|             250.0|\n","| Alto da Boa Vista|1423.7045454545455|\n","|          Anchieta|1921.3333333333333|\n","|           Andaraí|1165.7272727272727|\n","|              Anil|505.33962264150944|\n","|         Bancários|             223.2|\n","|             Bangu|1217.2941176470588|\n","|   Barra da Tijuca|1207.5908330545333|\n","|Barra de Guaratiba| 812.4934210526316|\n","|      Barros Filho|             325.0|\n","|           Benfica|             742.5|\n","|     Bento Ribeiro|             251.4|\n","|        Bonsucesso|           6429.25|\n","|          Botafogo| 943.8912721893491|\n","|      Brás de Pina|            135.64|\n","|          Cachambi|1186.3333333333333|\n","|            Cacuia| 140.3846153846154|\n","|              Caju|             941.5|\n","|           Camorim|           467.575|\n","+------------------+------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["## Estratégias de Otimização de UDFs"],"metadata":{"id":"VG_coMXuLuA_"}},{"cell_type":"markdown","source":["As UDFs (User-Defined Functions) no PySpark podem ser otimizadas para melhorar o desempenho e a eficiência do processamento de dados. Aqui estão algumas dicas para otimizar UDFs no PySpark:\n","\n","1. **Use funções internas sempre que possível**: As funções internas do PySpark são otimizadas para o processamento distribuído e geralmente têm melhor desempenho do que as UDFs. Portanto, tente usar funções internas sempre que possível e recorra a UDFs apenas quando necessário.\n","\n","2. **Use UDFs Pandas**: Se você precisa usar UDFs, opte por UDFs Pandas (vetoriais) sempre que possível, pois elas oferecem melhor desempenho em comparação com UDFs regulares (escalares). UDFs Pandas processam dados em lote usando DataFrames Pandas, o que reduz o tempo de execução e melhora o desempenho.\n","\n","3. **Evite conversões de tipo desnecessárias**: Ao definir UDFs, certifique-se de que os tipos de entrada e saída estão corretos, evitando conversões de tipo desnecessárias que possam afetar o desempenho.\n","\n","4. **Utilize Arrow para melhorar a conversão entre DataFrames Spark e Pandas**: Ao usar UDFs Pandas, habilite o Apache Arrow, uma biblioteca que melhora significativamente a conversão entre DataFrames Spark e Pandas.\n","\n","5. **Aplique UDFs apenas nas colunas necessárias**: Ao aplicar UDFs, selecione apenas as colunas necessárias em vez de aplicá-las em todo o DataFrame. Isso reduz a quantidade de dados processados e melhora a eficiência."],"metadata":{"id":"6rvX_XWaWu_V"}},{"cell_type":"markdown","source":["## Conclusão da sessão"],"metadata":{"id":"tZO9kaBcR9Ie"}},{"cell_type":"markdown","source":["1. Introdução às UDFs\n","2. Tipos de UDFs\n","3. Estratégias de otimização de UDFs"],"metadata":{"id":"yOqQuZT-cM9w"}},{"cell_type":"markdown","source":["## Exercício"],"metadata":{"id":"NCnmlbdJaB0S"}},{"cell_type":"markdown","source":["1. Qual é a diferença entre UDFs escalares e UDFs vetoriais (Pandas UDFs) no PySpark?\n","\n","2. Dado o seguinte código que define uma UDF escalar no PySpark, identifique e corrija quaisquer problemas relacionados à definição da função ou tipos de dados:\n","```\n","from pyspark.sql.functions import udf\n","from pyspark.sql.types import StringType\n","def concat_strings(s1, s2):\n","    return s1 + s2\n","concat_udf = udf(concat_strings, StringType())\n","```\n","\n","3. Converta a UDF escalar do exemplo da questão 2 em uma UDF vetorial (Pandas UDF) e aplique-a a um DataFrame de exemplo:\n","```\n","data = [(\"Hello\", \"World\"), (\"PySpark\", \"UDFs\"), (\"Data\", \"Processing\")]\n","columns = [\"String1\", \"String2\"]\n","df = spark.createDataFrame(data, columns)\n","```\n","\n","4. Suponha que você tenha um DataFrame com uma coluna chamada \"idade\" contendo a idade das pessoas. Crie e aplique uma UDF para criar uma nova coluna chamada \"idade_agrupada\" que classifica as pessoas em grupos etários com base na seguinte lógica:\n","- Menor de 18 anos: \"Under 18\"\n","- De 18 a 64 anos: \"18-64\"\n","- 65 anos ou mais: \"65+\"\n","\n","5. Qual é o impacto do uso do Apache Arrow na eficiência das UDFs Pandas no PySpark? Como você pode habilitar o suporte ao Apache Arrow em sua sessão Spark?"],"metadata":{"id":"uRc2Gm8iJpon"}}]}
