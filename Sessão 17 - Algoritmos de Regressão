{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["lJeDRY2Zc6Tn"],"authorship_tag":"ABX9TyOwilXleGAod7ZESrubqsVP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["###### Inicialização"],"metadata":{"id":"lJeDRY2Zc6Tn"}},{"cell_type":"code","source":["# instalar as dependências\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://dlcdn.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n","!tar xf spark-3.4.0-bin-hadoop3.tgz\n","!pip install -q findspark"],"metadata":{"id":"ty_kN91oadtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# configurar as variáveis de ambiente\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\"\n","\n","# tornar o pyspark \"importável\"\n","import findspark\n","findspark.init('spark-3.4.0-bin-hadoop3')"],"metadata":{"id":"GMGdL4xyc423"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# download do http para arquivo local\n","!wget --quiet --show-progress http://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2023-03-28/visualisations/listings.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRro-0ZO38tf","executionInfo":{"status":"ok","timestamp":1688332193050,"user_tz":180,"elapsed":1059,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"346c730f-0b29-4b63-bacd-9cd72d061689"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["listings.csv        100%[===================>]   4.37M  8.63MB/s    in 0.5s    \n"]}]},{"cell_type":"code","source":["!wget --quiet --show-progress https://www.arcgis.com/sharing/rest/content/items/3f382d42cf1d4f20bc489f5612481ede/data\n","!mv data natalidade_mortalidade_infantil.xls"],"metadata":{"id":"2kh8fSihFZ3a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688332194468,"user_tz":180,"elapsed":1432,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"4dc80a73-55bd-49a3-d1d4-01c4b5ef8b9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data                100%[===================>] 633.00K  2.00MB/s    in 0.3s    \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from matplotlib import pyplot as plt\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as f\n","from pyspark.ml.functions import vector_to_array\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import StringIndexer, OneHotEncoder, StandardScaler, MinMaxScaler, VectorAssembler\n","\n","spark = SparkSession.builder.master('local[*]').getOrCreate()\n","sc = spark.sparkContext"],"metadata":{"id":"MhZyuhxrFa_y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PySpark (Sessão 17)"],"metadata":{"id":"frFI5O7cZ5L8"}},{"cell_type":"markdown","source":["![img](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/250px-Apache_Spark_logo.svg.png)\n","\n","\n","https://spark.apache.org/docs/latest/api/python/"],"metadata":{"id":"pJCODccgTiQD"}},{"cell_type":"markdown","source":["## Recapitulando o que vimos antes..."],"metadata":{"id":"bGI5IDjEL5Z7"}},{"cell_type":"markdown","source":["1. Algoritmo de Random Forest\n","2. Algoritmo de Gradient-Boosted Trees\n","3. Algoritmo de Multilayer Perceptron (MLP)\n","\n","\n","\n"],"metadata":{"id":"um4D3ufho_5m"}},{"cell_type":"markdown","source":["## Introdução aos algoritmos de regressão com MLlib"],"metadata":{"id":"w_GXUXTITQuX"}},{"cell_type":"markdown","source":["A regressão é uma das técnicas de aprendizado supervisionado mais comumente usadas no campo da ciência de dados e aprendizado de máquina. Ela se concentra em modelar e entender a relação entre variáveis. Mais especificamente, envolve a predição de um valor contínuo, como o preço de uma casa, a temperatura de um dia ou o tempo de execução de um computador.\n","\n","Na biblioteca MLlib do PySpark, você encontrará vários algoritmos de regressão que podem ser usados para prever tais valores contínuos. Alguns dos algoritmos de regressão disponíveis incluem Regressão Linear, Regressão Generalizada, Regressão de Árvores de Decisão, Regressão de Florestas Aleatórias e Regressão de Gradient-Boosted Trees.\n","\n","A Regressão Linear, um dos algoritmos de regressão mais básicos e amplamente utilizados, assume uma relação linear entre as variáveis de entrada e a variável de saída. Em contraste, a Regressão Generalizada é mais flexível e permite escolher a distribuição dos erros e a função de ligação para transformar a combinação linear das variáveis de entrada na previsão para a variável de saída.\n","\n","Para dados mais complexos ou não lineares, os algoritmos de regressão baseados em árvores, como Regressão de Árvores de Decisão, Regressão de Florestas Aleatórias e Regressão de Gradient-Boosted Trees, são frequentemente usados. Esses algoritmos dividem as variáveis de entrada em segmentos ou \"árvores\" de decisão para minimizar a variância da variável de saída dentro de cada segmento.\n","\n","Usar a biblioteca MLlib do PySpark para implementar esses algoritmos em um ambiente distribuído pode ser incrivelmente eficiente e eficaz, especialmente quando se trabalha com grandes conjuntos de dados. Os algoritmos de regressão do MLlib são otimizados para processamento paralelo, tornando a análise de regressão rápida e escalável."],"metadata":{"id":"9u5HUHt0soIl"}},{"cell_type":"markdown","source":["## Preparando os dados"],"metadata":{"id":"ShKzmzPvFgZ6"}},{"cell_type":"code","source":["airbnb_rj = spark.read.csv(\"./listings.csv\", inferSchema=True, header=True)\n","airbnb_rj = airbnb_rj.where(airbnb_rj.host_id.cast(\"int\").isNotNull())\n","airbnb_rj = airbnb_rj.withColumn(\"host_id\", airbnb_rj.host_id.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"price_log\", f.log(airbnb_rj.price.cast('int') + 1))\n","airbnb_rj = airbnb_rj.withColumn(\"minimum_nights\", airbnb_rj.minimum_nights.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"number_of_reviews\", airbnb_rj.number_of_reviews.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"reviews_per_month\", airbnb_rj.reviews_per_month.cast('double'))\n","airbnb_rj = airbnb_rj.withColumn(\"availability_365\", airbnb_rj.availability_365.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"number_of_reviews_ltm\", airbnb_rj.number_of_reviews_ltm.cast('double'))\n","airbnb_rj = airbnb_rj.withColumn(\"calculated_host_listings_count\", airbnb_rj.calculated_host_listings_count.cast('int'))"],"metadata":{"id":"GZ36GBIvFivN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bairros_isolados = airbnb_rj.groupBy(airbnb_rj.neighbourhood). \\\n","                                agg(f.count(\"id\").alias(\"contagem\")). \\\n","                                where(\"contagem < 10\").select(airbnb_rj.neighbourhood). \\\n","                                toPandas().neighbourhood.tolist()\n","airbnb_rj = airbnb_rj.where(~airbnb_rj.neighbourhood.isin(bairros_isolados)) #existe apenas um ítem na base"],"metadata":{"id":"jNzN290MFlF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["natal_mort = pd.read_excel(open('natalidade_mortalidade_infantil.xls', 'rb'), sheet_name='2019',header=4)\n","natal_mort = natal_mort.drop([0,1,2]).drop(list(range(167,174))).iloc[:,[1,2,4,6,8,10]]\n","natal_mort.columns = [\"bairro\",\"obito_precoce\",\"obito_tardio\",\"obito_neonatal\",\"obito_1ano\",\"nascidos\"]\n","natal_mort.bairro = natal_mort.bairro.str.strip()\n","complementar = spark.createDataFrame(natal_mort)"],"metadata":{"id":"bE3ERlTNFlZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["airbnb_rj = airbnb_rj.join(complementar, on=[airbnb_rj.neighbourhood == complementar.bairro])"],"metadata":{"id":"nD5uu_PnFl9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["airbnb_rj = airbnb_rj.withColumn(\"obito_precoce\", airbnb_rj.obito_precoce.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"obito_tardio\", airbnb_rj.obito_tardio.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"obito_neonatal\", airbnb_rj.obito_neonatal.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"obito_1ano\", airbnb_rj.obito_1ano.cast('int'))\n","airbnb_rj = airbnb_rj.withColumn(\"nascidos\", airbnb_rj.nascidos.cast('int'))"],"metadata":{"id":"qK5IhZD9NQM7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["categoricas = [\"neighbourhood\", \"room_type\"]\n","continuas = [\"minimum_nights\", \"number_of_reviews\", \"reviews_per_month\",\n","     \"calculated_host_listings_count\", \"availability_365\", \"number_of_reviews_ltm\", \"obito_precoce\",\n","     \"obito_tardio\", \"obito_neonatal\", \"obito_1ano\", \"nascidos\"]\n","resposta = [\"price_log\"]"],"metadata":{"id":"S72fwj3rFqzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["airbnb_rj = airbnb_rj.fillna(0, subset = continuas)"],"metadata":{"id":"5iGhUCoaFrB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["treino, teste = airbnb_rj.select(*(categoricas + continuas + resposta)).randomSplit([0.7, 0.3])"],"metadata":{"id":"QOCEpJz5Fzby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stages = []"],"metadata":{"id":"XLURzI4VF6fG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Transformaremos as colunas categóricas em numéricas"],"metadata":{"id":"gLSYPuaBZo9o"}},{"cell_type":"code","source":["for col in categoricas:\n","  # Indexação de categoria\n","  string_indexer = StringIndexer(inputCol=col, outputCol=col + \"_idx\")\n","  # One-hot encoding\n","  encoder = OneHotEncoder(inputCols=[string_indexer.getOutputCol()], outputCols=[col + \"_ohe\"])\n","  stages += [string_indexer, encoder]"],"metadata":{"id":"0Kp1EWzVYGIg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Combinaremos todas as colunas de recurso em um vetor"],"metadata":{"id":"5TYA-N4gb3UM"}},{"cell_type":"code","source":["assembler_inputs = [c + \"_ohe\" for c in categoricas] + continuas\n","assembler = VectorAssembler(inputCols=assembler_inputs, outputCol='features')\n","stages += [assembler]"],"metadata":{"id":"jdsibzyaVDrU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Escalaremos as variáveis utilizando o StandardScaler"],"metadata":{"id":"CHw5VHetF_PU"}},{"cell_type":"code","source":["scaler = StandardScaler(inputCol='features', outputCol='features_scaled')\n","stages += [scaler]"],"metadata":{"id":"4qYE4Md55GjX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Transformaremos os dados para estarem prontos para aplicarmos os modelos"],"metadata":{"id":"t738mMASGSaN"}},{"cell_type":"code","source":["pipeline = Pipeline(stages=stages)\n","preparacao = pipeline.fit(treino)"],"metadata":{"id":"WhAdhX1lY_WE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["treino = preparacao.transform(treino).select('features_scaled','price_log')\n","teste = preparacao.transform(teste).select('features_scaled','price_log')"],"metadata":{"id":"Ryhb67VmcNWw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Regressão Linear"],"metadata":{"id":"7upOR1nqsn_d"}},{"cell_type":"markdown","source":["Este é o algoritmo de regressão mais simples e comum. Ele assume uma relação linear entre as variáveis de entrada (X) e a variável de saída (Y). Quando treinamos um modelo de regressão linear, o objetivo é encontrar os coeficientes que minimizam a soma dos quadrados dos resíduos (a diferença entre o valor previsto e o valor real)."],"metadata":{"id":"0Xrlucm7sn24"}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\n","\n","lr = LinearRegression(featuresCol = 'features_scaled', labelCol='price_log')\n","lr_model = lr.fit(treino)"],"metadata":{"id":"Wo37Kbc-s-oc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n","\n","predictions = lr_model.transform(teste)\n","\n","evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price_log\", metricName=\"rmse\")\n","rmse = evaluator.evaluate(predictions)\n","print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUoKen3RPrqT","executionInfo":{"status":"ok","timestamp":1688332851609,"user_tz":180,"elapsed":1158,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"370016d7-49fb-45f6-cecb-6e6725eba6ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Root Mean Squared Error (RMSE) on test data = 0.804075\n"]}]},{"cell_type":"markdown","source":["## Regressão Generalizada"],"metadata":{"id":"S-zcbhElslb8"}},{"cell_type":"markdown","source":["Enquanto a regressão linear faz suposições específicas sobre a relação entre as variáveis de entrada e a variável de saída, a regressão generalizada permite mais flexibilidade. Você pode escolher a distribuição dos erros e a função de ligação que transforma a combinação linear das variáveis de entrada na previsão para a variável de saída. Isso torna a regressão generalizada útil para lidar com uma variedade de diferentes tipos de problemas de regressão."],"metadata":{"id":"QkX-b_LUtAbl"}},{"cell_type":"code","source":["from pyspark.ml.regression import GeneralizedLinearRegression\n","\n","glr = GeneralizedLinearRegression(featuresCol='features_scaled', labelCol='price_log', family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)\n","glr_model = glr.fit(treino)"],"metadata":{"id":"L9itlBo-tN7r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = glr_model.transform(teste)\n","\n","rmse = evaluator.evaluate(predictions)\n","print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{"id":"ZVGrShYyTib8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688332893898,"user_tz":180,"elapsed":941,"user":{"displayName":"Luan Corumba","userId":"07892592111474770617"}},"outputId":"e8397f21-efe1-4d2c-aaa7-93f75f0f51ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Root Mean Squared Error (RMSE) on test data = 0.80721\n"]}]},{"cell_type":"markdown","source":["## Conclusão da sessão"],"metadata":{"id":"u20jBuvdTcBG"}},{"cell_type":"markdown","source":["1. Introdução aos algoritmos de regressão do MLlib\n","2. Algoritmo de Regressão Linear\n","3. Algoritmo de Regressão Generalizada"],"metadata":{"id":"qmkkKK_sTdan"}},{"cell_type":"markdown","source":["## Exercício"],"metadata":{"id":"NCnmlbdJaB0S"}},{"cell_type":"markdown","source":["1. Dado um conjunto de dados com várias características (features) e uma variável alvo (target), implemente um modelo de Regressão Linear. Como você avaliaria a precisão desse modelo?\n","\n","2. Em quais situações você escolheria usar Regressão Linear sobre Regressão Generalizada?\n","\n","3. Crie um código PySpark para executar Regressão Generalizada em um conjunto de dados hipotético. Certifique-se de mencionar como você escolheu a família de distribuições e a função de ligação.\n","\n","4. Em que situações a Regressão Generalizada é uma escolha mais adequada em comparação com a Regressão Linear?\n","\n","5. Explique como o PySpark otimiza as operações de regressão quando está trabalhando em um cluster distribuído."],"metadata":{"id":"_7PipL2eh3hH"}}]}